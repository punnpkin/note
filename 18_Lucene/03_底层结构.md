# 三、Lucene底层存储结构

## 1. 索引目录：

```
segments_1
write.lock
_0.cfe
_0.cfs
_0.si
```

## 2. 段：

Lunece索引通过分段存储的方式，解决了单个文件难以维护的缺点。

### 数据操作过程：

- 新增。当有新的数据需要创建索引时，**由于段的不变性**，所以选择新建一个段来存储新增的数据。

- 删除。当需要删除数据时，由于数据所在的段只可读，不可写，所以Lucene在索引文件下新增了一个.del的文件，用来专门存储被删除的数据id。当查询时，被删除的数据还是可以被查到的，只是在进行文档链表合并时，才把已经删除的数据过滤掉。被删除的数据在进行段合并时才会真正被移除。

- 更新。更新的操作其实就是删除和新增的组合，先在.del文件中记录旧数据，再在新段中添加一条更新后的数据。

### **段不变性的优点**：

- 不需要锁。因为数据不会更新，所以不用考虑多线程下的读写不一致情况。
- 可以常驻内存。段在被加载到内存后，由于具有不变性，所以只要内存的空间足够大，就可以长时间驻存，大部分查询请求会直接访问内存，而不需要访问磁盘，使得查询的性能有很大的提升。
- 缓存友好。在段的声明周期内始终有效，不需要在每次数据更新时被重建。
- 增量创建。分段可以做到增量创建索引，可以轻量级地对数据进行更新，由于每次创建的成本很低，所以可以频繁地更新数据，使系统接近实时更新。

缺点：

- 删除是标记的方式，比较浪费
- 更新，是两个所作组成
- 每次新增数据都需要新增段
- 查询需要过滤

为了提升写的性能，Lucene并没有每新增一条数据就增加一个段，而是采用延迟写的策略，每当有新增的数据时，就将其先写入内存中，然后批量写入磁盘中。若有一个段被写到硬盘，就会生成一个提交点，提交点就是一个用来记录所有提交后的段信息的文件。一个段一旦拥有了提交点，就说明这个段只有读的权限，失去了写的权限；相反，当段在内存中时，就只有写数据的权限，而不具备读数据的权限，所以也就不能被检索了。从严格意义上来说，Lucene或者Elasticsearch并不能被称为实时的搜索引擎，只能被称为准实时的搜索引擎。

### **写索引的流程**：

- 新数据暂时写入内存中，数据量很多时，再提交到磁盘上
- 在达到触发条件以后，会将内存中缓存的数据一次性写入磁盘中，并生成提交点
- 清空内存，等待新的数据写入

### 段合并的策略：

长时间的积累，会导致在索引中存在大量的段，当索引中段的数量太多时，不仅会严重消耗服务器的资源，还会影响检索的性能。

根据段的大小先将段进行分组，再将属于同一组的段进行合并。但是由于对超级大的段的合并需要消耗更多的资源，所以Lucene会在段的大小达到一定规模，或者段里面的数据量达到一定条数时，不会再进行合并。**Lucene的段合并主要集中在对中小段的合并上**，这样既可以避免对大段进行合并时消耗过多的服务器资源，也可以很好地控制索引中段的数量。

**段合并的参数：**

- mergeFactor：每次合并时参与**合并的段的最少数量**，当同一组的段的数量达到此值时开始合并，如果小于此值则不合并，这样做可以减少段合并的频率，其默认值为10。
- SegmentSize：指段的实际大小，单位为字节。
- minMergeSize：小于这个值的段会被分到一组，这样可以加速小片段的合并。
- maxMergeSize：若一个段的文本数量大于此值，就不再参与合并，因为大段合并会消耗更多的资源。

**段合并相关的动作是：**

- 段分组：大小相近的段分到一组
- 段合并：同一组中的段合并为更大的段

## 3. 索引库文件

|     Name      |   .file    |                           说明                            |
| :-----------: | :--------: | :-------------------------------------------------------: |
| Segment Info  |    .si     |                 保存了索引段的元数据信息                  |
| Compound File | .cfs，.cfe | 一个可选的虚拟文件，把所有索引信息都存储到复合索 引文件中 |
|   Lock File   | write.lock |         防止多个IndexWriter同时写到一份索引文件中         |
| Segments File | segments_N |         保存了一个提交点（a commit point）的信息          |

## 4. 词典构建

为何Lucene大数据量搜索快, 要分两部分来看 :

- 一点是因为底层的倒排索引存储结构
- 另一点就是查询关键字的时候速度快, 因为词典的索引结构

**跳表**

优点：结构简单， 跳跃间隔、级数可控。Lucene3.0之前使用的也是跳跃表结构，，但跳跃表在Lucene其他地方还有应用如倒排表合并和文档号索引。

缺点 ：模糊查询支持不好.

**FST**

优点：内存占用低，压缩率高

缺点：结构复杂，输入要求有序

已知FST要求输入有序，所以Lucene会将解析出来的文档单词预先排序，然后构建FST。

我们假设输入为abd,abe,acf,acg，那么整个构建过程如下：

```
    a           a         a              a
   /           /         / \            / \
  b           b         b   c          b   c
 /           / \       / \  /         / \ / \
d           d   e     d  e f         d  e f  g
```

## 5. 优化

**磁盘IO**

- `config.setMaxBufferedDocs`(100000); （设置缓存）控制写入一个新的segment前内存中保存的document的数目，设置较大的数目可以加快建索引速度。 **数值越大索引速度越快, 但是会消耗更多的内存。**
- `indexWriter.forceMerge`(文档数量); 设置N个文档合并为一个段。 **数值越大索引速度越快, 搜索速度越慢; 值越小索引速度越慢, 搜索速度越快。** 更高的值意味着索引期间更低的段合并开销，但同时也意味着更慢的搜索速度，因为此时的索引通常会包含更多的段。如果该值设置的过高，能获得更高的索引性能。但若在最后进行索引优化，那么较低的值会带来更快的搜索速度，因为在索引操作期间程序会利用并发机制完成段合并操作。故建议对程序分别进行高低多种值的测试，利用计算机的实际性能来告诉你最优值。

## 6. 相关度排序

1**. 分值**

Lucene是在用户进行检索时实时根据搜索的关键字计算出来的，分两步：

1. 计算出词（Term）的权重
2. 根据词的权重值，计算文档相关度得分。

**2. 权重**

确索引的最小单位是一个Term(索引词典中的一个词)，搜索也是要从Term中搜索，再根据Term找到文档，Term对文档的重要性称为权重，影响Term权重有两个因素：

- Term Frequency (tf)： 指此Term在此文档中出现了多少次。tf 越大说明越重要。 词(Term)在文档 中出现的次数越多，说明此词(Term)对该文档越重要，如“Lucene”这个词，在文档中出现的次数 很多，说明该文档主要就是讲Lucene技术的。
- Document Frequency (df)： 指有多少文档包含次Term。df 越大说明越不重要。 比如，在一篇英语文档中，this出现的次数更多，就说明越重要吗？不是的，有越多的文档包含此词(Term), 说明 此词(Term)太普通，不足以区分这些文档，因而重要性越低。

**3. 排序**

boost是一个加权值（默认加权值为1.0f），它可以影响权重的计算。

- 在索引时对某个文档中的field设置加权值高，在搜索时匹配到这个文档就可能排在前边。
- 在搜索时对某个域进行加权，在进行组合域查询时，匹配到加权值高的域最后计算的相关度得分就高。

设置boost是给域（field）或者Document设置的。